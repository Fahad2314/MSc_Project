{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "from datetime import datetime, timedelta, date\n",
    "import requests\n",
    "import json \n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape\n",
    "from keras.layers import Convolution1D, MaxPooling1D\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### read in the flattened dataframes with the labels\n",
    "MSFT_df = pd.read_csv(\"/Users/fahad/project_repo/data/external/MSFT_flat.csv\", index_col=0)\n",
    "AAPL_df = pd.read_csv(\"/Users/fahad/project_repo/data/external/AAPL_flat.csv\",index_col=0)\n",
    "AMZN_df = pd.read_csv(\"/Users/fahad/project_repo/data/external/AMZN_flat.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>351</th>\n",
       "      <th>352</th>\n",
       "      <th>353</th>\n",
       "      <th>354</th>\n",
       "      <th>355</th>\n",
       "      <th>356</th>\n",
       "      <th>357</th>\n",
       "      <th>358</th>\n",
       "      <th>359</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1998-03-31</th>\n",
       "      <td>0.429339</td>\n",
       "      <td>0.425285</td>\n",
       "      <td>0.432434</td>\n",
       "      <td>0.426907</td>\n",
       "      <td>0.020233</td>\n",
       "      <td>0.627285</td>\n",
       "      <td>0.373432</td>\n",
       "      <td>0.500535</td>\n",
       "      <td>0.519246</td>\n",
       "      <td>0.231693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703805</td>\n",
       "      <td>0.005767</td>\n",
       "      <td>0.226505</td>\n",
       "      <td>0.019309</td>\n",
       "      <td>0.457683</td>\n",
       "      <td>0.712130</td>\n",
       "      <td>0.453455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-04-30</th>\n",
       "      <td>0.444974</td>\n",
       "      <td>0.443069</td>\n",
       "      <td>0.449092</td>\n",
       "      <td>0.441714</td>\n",
       "      <td>0.005799</td>\n",
       "      <td>0.403578</td>\n",
       "      <td>0.305363</td>\n",
       "      <td>0.475177</td>\n",
       "      <td>0.588950</td>\n",
       "      <td>0.276414</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844894</td>\n",
       "      <td>0.012340</td>\n",
       "      <td>0.954846</td>\n",
       "      <td>0.966738</td>\n",
       "      <td>0.509452</td>\n",
       "      <td>0.514381</td>\n",
       "      <td>0.640977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 361 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0         1         2         3         4         5  \\\n",
       "1998-03-31  0.429339  0.425285  0.432434  0.426907  0.020233  0.627285   \n",
       "1998-04-30  0.444974  0.443069  0.449092  0.441714  0.005799  0.403578   \n",
       "\n",
       "                   6         7         8         9  ...       351       352  \\\n",
       "1998-03-31  0.373432  0.500535  0.519246  0.231693  ...  0.703805  0.005767   \n",
       "1998-04-30  0.305363  0.475177  0.588950  0.276414  ...  0.844894  0.012340   \n",
       "\n",
       "                 353       354       355       356       357  358  359  Label  \n",
       "1998-03-31  0.226505  0.019309  0.457683  0.712130  0.453455  0.0  0.0      1  \n",
       "1998-04-30  0.954846  0.966738  0.509452  0.514381  0.640977  0.0  0.0      1  \n",
       "\n",
       "[2 rows x 361 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSFT_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#vertically stack the MSFT and AAPL dataframes on top of eachother\n",
    "df = pd.concat([MSFT_df, AAPL_df], axis=0)\n",
    "#vertically stack the MSFT&AAPL df and the AMZN dataframe ontop of eachother\n",
    "df = pd.concat([df,AMZN_df],axis = 0)\n",
    "#set index to date\n",
    "#df.set_index(\"Date\")\n",
    "\n",
    "y = df.Label # define the target variable (dependent variable) as y\n",
    "\n",
    "df = df.drop(['Label'], axis =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360\n",
      "537\n"
     ]
    }
   ],
   "source": [
    "#define the target variable as y \n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.3)\n",
    "#print (X_train.head(5))\n",
    "print(X_train.shape[1])\n",
    "print(X_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_timeseries_classifier(sample_num,window_size, filter_length, nb_input_series=1, nb_outputs=1, nb_filter=16):\n",
    "    \"\"\":Return: a Keras Model for predicting the next value in a timeseries given a fixed-size lookback window of previous values.\n",
    "    The model can handle multiple input timeseries (`nb_input_series`) and multiple prediction targets (`nb_outputs`).\n",
    "    :param int window_size: The number of previous timeseries values to use as input features.  Also called lag or lookback.\n",
    "    :param int nb_input_series: The number of input timeseries; 1 for a single timeseries.\n",
    "      The `X` input to ``fit()`` should be an array of shape ``(n_instances, window_size, nb_input_series)``; each instance is\n",
    "      a 2D array of shape ``(window_size, nb_input_series)``.  For example, for `window_size` = 3 and `nb_input_series` = 1 (a\n",
    "      single timeseries), one instance could be ``[[0], [1], [2]]``. See ``make_timeseries_instances()``.\n",
    "    :param int nb_outputs: The output dimension, often equal to the number of inputs.\n",
    "      For each input instance (array with shape ``(window_size, nb_input_series)``), the output is a vector of size `nb_outputs`,\n",
    "      usually the value(s) predicted to come after the last value in that input instance, i.e., the next value\n",
    "      in the sequence. The `y` input to ``fit()`` should be an array of shape ``(n_instances, nb_outputs)``.\n",
    "    :param int filter_length: the size (along the `window_size` dimension) of the sliding window that gets convolved with\n",
    "      each position along each instance. The difference between 1D and 2D convolution is that a 1D filter's \"height\" is fixed\n",
    "      to the number of input timeseries (its \"width\" being `filter_length`), and it can only slide along the window\n",
    "      dimension.  This is useful as generally the input timeseries have no spatial/ordinal relationship, so it's not\n",
    "      meaningful to look for patterns that are invariant with respect to subsets of the timeseries.\n",
    "    :param int nb_filter: The number of different filters to learn (roughly, input patterns to recognize).\n",
    "    \"\"\"\n",
    "    model = Sequential((\n",
    "        # The first conv layer learns `nb_filter` filters (aka kernels), each of size ``(filter_length, nb_input_series)``.\n",
    "        # Its output will have shape (None, window_size - filter_length + 1, nb_filter), i.e., for each position in\n",
    "        # the input timeseries, the activation of each filter at that position.\n",
    "        Convolution1D(nb_filter=nb_filter, filter_length=filter_length, activation='relu', input_shape=(window_size,nb_input_series)),\n",
    "        MaxPooling1D(),     # Downsample the output of convolution by 2X.\n",
    "        Convolution1D(nb_filter=nb_filter, filter_length=filter_length, activation='relu'),\n",
    "        MaxPooling1D(),\n",
    "        Flatten(),\n",
    "        Dense(nb_outputs, activation='sigmoid'),     # For binary classification, change the activation to 'sigmoid'\n",
    "    ))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # To perform (binary) classification instead:\n",
    "    # model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", input_shape=(360, 1), filters=16, kernel_size=3)`\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0717 16:36:03.042312 4589483456 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", filters=16, kernel_size=3)`\n",
      "W0717 16:36:03.059471 4589483456 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0717 16:36:03.061857 4589483456 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0717 16:36:03.085327 4589483456 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0717 16:36:03.120315 4589483456 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0717 16:36:03.139325 4589483456 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0717 16:36:03.143057 4589483456 deprecation.py:323] From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_1 = make_timeseries_classifier(X_train.shape[0],X_train.shape[1],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 358, 16)           64        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 179, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 177, 16)           784       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 88, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1408)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 1409      \n",
      "=================================================================\n",
      "Total params: 2,257\n",
      "Trainable params: 2,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0717 16:36:03.386466 4589483456 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 483 samples, validate on 54 samples\n",
      "Epoch 1/100\n",
      "483/483 [==============================] - 1s 2ms/step - loss: 0.6899 - acc: 0.5714 - val_loss: 0.6567 - val_acc: 0.5926\n",
      "Epoch 2/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.6543 - acc: 0.6232 - val_loss: 0.6258 - val_acc: 0.6111\n",
      "Epoch 3/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.5968 - acc: 0.6729 - val_loss: 0.5273 - val_acc: 0.6852\n",
      "Epoch 4/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.5404 - acc: 0.7288 - val_loss: 0.5326 - val_acc: 0.7037\n",
      "Epoch 5/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.5215 - acc: 0.7412 - val_loss: 0.4708 - val_acc: 0.7037\n",
      "Epoch 6/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.4881 - acc: 0.7764 - val_loss: 0.4760 - val_acc: 0.7037\n",
      "Epoch 7/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.4607 - acc: 0.7930 - val_loss: 0.5117 - val_acc: 0.7407\n",
      "Epoch 8/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.4417 - acc: 0.8012 - val_loss: 0.4950 - val_acc: 0.6667\n",
      "Epoch 9/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.4341 - acc: 0.7909 - val_loss: 0.5332 - val_acc: 0.7222\n",
      "Epoch 10/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.4256 - acc: 0.8075 - val_loss: 0.4772 - val_acc: 0.7407\n",
      "Epoch 11/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.4158 - acc: 0.8054 - val_loss: 0.4762 - val_acc: 0.7407\n",
      "Epoch 12/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.4044 - acc: 0.8075 - val_loss: 0.4847 - val_acc: 0.7407\n",
      "Epoch 13/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.4019 - acc: 0.8261 - val_loss: 0.4693 - val_acc: 0.7593\n",
      "Epoch 14/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.3900 - acc: 0.8302 - val_loss: 0.4888 - val_acc: 0.7593\n",
      "Epoch 15/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.3899 - acc: 0.8219 - val_loss: 0.4840 - val_acc: 0.7593\n",
      "Epoch 16/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.3730 - acc: 0.8364 - val_loss: 0.4778 - val_acc: 0.7963\n",
      "Epoch 17/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.3730 - acc: 0.8385 - val_loss: 0.4781 - val_acc: 0.7593\n",
      "Epoch 18/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.3661 - acc: 0.8364 - val_loss: 0.5760 - val_acc: 0.7407\n",
      "Epoch 19/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.3625 - acc: 0.8427 - val_loss: 0.4632 - val_acc: 0.7593\n",
      "Epoch 20/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.3502 - acc: 0.8592 - val_loss: 0.5090 - val_acc: 0.7037\n",
      "Epoch 21/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.3431 - acc: 0.8468 - val_loss: 0.5595 - val_acc: 0.7407\n",
      "Epoch 22/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.3469 - acc: 0.8447 - val_loss: 0.5099 - val_acc: 0.7407\n",
      "Epoch 23/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.3346 - acc: 0.8592 - val_loss: 0.5041 - val_acc: 0.7593\n",
      "Epoch 24/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.3420 - acc: 0.8571 - val_loss: 0.4912 - val_acc: 0.7778\n",
      "Epoch 25/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.3335 - acc: 0.8696 - val_loss: 0.4775 - val_acc: 0.7593\n",
      "Epoch 26/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.3167 - acc: 0.8675 - val_loss: 0.5107 - val_acc: 0.7778\n",
      "Epoch 27/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.3100 - acc: 0.8675 - val_loss: 0.5543 - val_acc: 0.7778\n",
      "Epoch 28/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.3224 - acc: 0.8654 - val_loss: 0.5066 - val_acc: 0.7963\n",
      "Epoch 29/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.3086 - acc: 0.8820 - val_loss: 0.5749 - val_acc: 0.7593\n",
      "Epoch 30/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.3101 - acc: 0.8489 - val_loss: 0.5740 - val_acc: 0.7407\n",
      "Epoch 31/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.3012 - acc: 0.8758 - val_loss: 0.5241 - val_acc: 0.7778\n",
      "Epoch 32/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.2921 - acc: 0.8841 - val_loss: 0.5713 - val_acc: 0.7407\n",
      "Epoch 33/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.2981 - acc: 0.8654 - val_loss: 0.5049 - val_acc: 0.7778\n",
      "Epoch 34/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.2857 - acc: 0.8861 - val_loss: 0.5522 - val_acc: 0.7963\n",
      "Epoch 35/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.2799 - acc: 0.9006 - val_loss: 0.5339 - val_acc: 0.7593\n",
      "Epoch 36/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.2830 - acc: 0.8737 - val_loss: 0.5596 - val_acc: 0.7963\n",
      "Epoch 37/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.2763 - acc: 0.9089 - val_loss: 0.6130 - val_acc: 0.7593\n",
      "Epoch 38/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.2663 - acc: 0.8882 - val_loss: 0.5997 - val_acc: 0.7222\n",
      "Epoch 39/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.2657 - acc: 0.8986 - val_loss: 0.5892 - val_acc: 0.7407\n",
      "Epoch 40/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.2622 - acc: 0.8986 - val_loss: 0.5787 - val_acc: 0.7407\n",
      "Epoch 41/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.2615 - acc: 0.8944 - val_loss: 0.5295 - val_acc: 0.8148\n",
      "Epoch 42/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.2586 - acc: 0.8986 - val_loss: 0.5843 - val_acc: 0.7593\n",
      "Epoch 43/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.2497 - acc: 0.9006 - val_loss: 0.6248 - val_acc: 0.7593\n",
      "Epoch 44/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.2467 - acc: 0.9172 - val_loss: 0.5132 - val_acc: 0.7963\n",
      "Epoch 45/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.2447 - acc: 0.9027 - val_loss: 0.6279 - val_acc: 0.7407\n",
      "Epoch 46/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.2385 - acc: 0.9193 - val_loss: 0.5556 - val_acc: 0.7778\n",
      "Epoch 47/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.2281 - acc: 0.9110 - val_loss: 0.5556 - val_acc: 0.7963\n",
      "Epoch 48/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.2294 - acc: 0.9027 - val_loss: 0.5910 - val_acc: 0.7593\n",
      "Epoch 49/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.2280 - acc: 0.9130 - val_loss: 0.5815 - val_acc: 0.7778\n",
      "Epoch 50/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.2155 - acc: 0.9130 - val_loss: 0.6376 - val_acc: 0.7963\n",
      "Epoch 51/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.2019 - acc: 0.9337 - val_loss: 0.5837 - val_acc: 0.7593\n",
      "Epoch 52/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.2170 - acc: 0.9151 - val_loss: 0.6278 - val_acc: 0.7778\n",
      "Epoch 53/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.2010 - acc: 0.9275 - val_loss: 0.7682 - val_acc: 0.7593\n",
      "Epoch 54/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.2154 - acc: 0.9130 - val_loss: 0.6361 - val_acc: 0.7963\n",
      "Epoch 55/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.2104 - acc: 0.9213 - val_loss: 0.6289 - val_acc: 0.7778\n",
      "Epoch 56/100\n",
      "483/483 [==============================] - 1s 2ms/step - loss: 0.2027 - acc: 0.9172 - val_loss: 0.6154 - val_acc: 0.7593\n",
      "Epoch 57/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.1942 - acc: 0.9255 - val_loss: 0.6487 - val_acc: 0.7778\n",
      "Epoch 58/100\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 0.1986 - acc: 0.9234 - val_loss: 0.6197 - val_acc: 0.7593\n",
      "Epoch 59/100\n",
      "433/483 [=========================>....] - ETA: 0s - loss: 0.1894 - acc: 0.9330"
     ]
    }
   ],
   "source": [
    "history=model_1.fit(np.array(X_train).reshape((*X_train.shape,1)),np.array(y_train).reshape((*y_train.shape,1)),\n",
    "            validation_split=0.10, epochs=100\n",
    "            ,batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict The Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the predictions using the the model we have created, note the input must be a np.array and a 3d tensor\n",
    "predictions = model_1.predict_classes(np.array(X_test).reshape((*X_test.shape,1)),batch_size = X_test.shape[0], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the accuracy of the training set  and the validation set of the model\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=[20,20])\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.ylabel(['Accuracy'])\n",
    "plt.xlabel(['Epochs'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#import h5py\n",
    "\n",
    "#stopping callback to get the validation \n",
    "#keras.callbacks.EarlyStopping(monitor_metric='val accuracy', mode='max', patience='callback_patience')\n",
    "\n",
    "#saving criteria\n",
    "#keras.callbacks.ModelCheckpoint(model=name of model.h5, \n",
    "#monitor=monitor_metric = 'val_accuracy' mode='max',savE_best_only=True)\n",
    "\n",
    "#in model.fit(.........callbacks=callback_list )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

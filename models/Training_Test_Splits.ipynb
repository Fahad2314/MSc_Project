{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "from datetime import datetime, timedelta, date\n",
    "import requests\n",
    "import json \n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape\n",
    "from keras.layers import Convolution1D, MaxPooling1D\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the flattened dataframes with the labels\n",
    "MSFT_df = pd.read_csv(\"/Users/fahad/project_repo/data/external/MSFT_flat.csv\")\n",
    "AAPL_df = pd.read_csv(\"/Users/fahad/project_repo/data/external/AAPL_flat.csv\")\n",
    "AMZN_df = pd.read_csv(\"/Users/fahad/project_repo/data/external/AMZN_flat.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vertically stack the MSFT and AAPL dataframes on top of eachother\n",
    "df = pd.concat([MSFT_df, AAPL_df], axis=0)\n",
    "#vertically stack the MSFT&AAPL df and the AMZN dataframe ontop of eachother\n",
    "df = pd.concat([df,AMZN_df],axis = 0)\n",
    "\n",
    "y = df.Label # define the target variable (dependent variable) as y\n",
    "\n",
    "df = df.drop(['Date','Label'], axis =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360\n",
      "541\n"
     ]
    }
   ],
   "source": [
    "#define the target variable as y \n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.3)\n",
    "#print (X_train.head(5))\n",
    "print(X_train.shape[1])\n",
    "print(X_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_timeseries_classifier(sample_num,window_size, filter_length, nb_input_series=1, nb_outputs=1, nb_filter=16):\n",
    "    \"\"\":Return: a Keras Model for predicting the next value in a timeseries given a fixed-size lookback window of previous values.\n",
    "    The model can handle multiple input timeseries (`nb_input_series`) and multiple prediction targets (`nb_outputs`).\n",
    "    :param int window_size: The number of previous timeseries values to use as input features.  Also called lag or lookback.\n",
    "    :param int nb_input_series: The number of input timeseries; 1 for a single timeseries.\n",
    "      The `X` input to ``fit()`` should be an array of shape ``(n_instances, window_size, nb_input_series)``; each instance is\n",
    "      a 2D array of shape ``(window_size, nb_input_series)``.  For example, for `window_size` = 3 and `nb_input_series` = 1 (a\n",
    "      single timeseries), one instance could be ``[[0], [1], [2]]``. See ``make_timeseries_instances()``.\n",
    "    :param int nb_outputs: The output dimension, often equal to the number of inputs.\n",
    "      For each input instance (array with shape ``(window_size, nb_input_series)``), the output is a vector of size `nb_outputs`,\n",
    "      usually the value(s) predicted to come after the last value in that input instance, i.e., the next value\n",
    "      in the sequence. The `y` input to ``fit()`` should be an array of shape ``(n_instances, nb_outputs)``.\n",
    "    :param int filter_length: the size (along the `window_size` dimension) of the sliding window that gets convolved with\n",
    "      each position along each instance. The difference between 1D and 2D convolution is that a 1D filter's \"height\" is fixed\n",
    "      to the number of input timeseries (its \"width\" being `filter_length`), and it can only slide along the window\n",
    "      dimension.  This is useful as generally the input timeseries have no spatial/ordinal relationship, so it's not\n",
    "      meaningful to look for patterns that are invariant with respect to subsets of the timeseries.\n",
    "    :param int nb_filter: The number of different filters to learn (roughly, input patterns to recognize).\n",
    "    \"\"\"\n",
    "    model = Sequential((\n",
    "        # The first conv layer learns `nb_filter` filters (aka kernels), each of size ``(filter_length, nb_input_series)``.\n",
    "        # Its output will have shape (None, window_size - filter_length + 1, nb_filter), i.e., for each position in\n",
    "        # the input timeseries, the activation of each filter at that position.\n",
    "        Convolution1D(nb_filter=nb_filter, filter_length=filter_length, activation='relu', input_shape=(window_size,nb_input_series)),\n",
    "        MaxPooling1D(),     # Downsample the output of convolution by 2X.\n",
    "        Convolution1D(nb_filter=nb_filter, filter_length=filter_length, activation='relu'),\n",
    "        MaxPooling1D(),\n",
    "        Flatten(),\n",
    "        Dense(nb_outputs, activation='sigmoid'),     # For binary classification, change the activation to 'sigmoid'\n",
    "    ))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # To perform (binary) classification instead:\n",
    "    # model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", input_shape=(360, 1), filters=16, kernel_size=3)`\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", filters=16, kernel_size=3)`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_1 = make_timeseries_classifier(X_train.shape[0],X_train.shape[1],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_25 (Conv1D)           (None, 358, 16)           64        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 179, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 177, 16)           784       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 88, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 1408)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 1409      \n",
      "=================================================================\n",
      "Total params: 2,257\n",
      "Trainable params: 2,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(trainX, trainy, testX, testy,model):\n",
    "    #sometimes batch size must be a divisor of rows\n",
    "    verbose, epochs, batch_size = 1, 10, 32\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "541/541 [==============================] - 1s 1ms/step - loss: 0.4017 - acc: 0.8429\n",
      "Epoch 2/20\n",
      "541/541 [==============================] - 1s 1ms/step - loss: 0.2785 - acc: 0.8928\n",
      "Epoch 3/20\n",
      "541/541 [==============================] - 1s 1ms/step - loss: 0.2262 - acc: 0.9094\n",
      "Epoch 4/20\n",
      "541/541 [==============================] - 1s 1ms/step - loss: 0.2035 - acc: 0.9131\n",
      "Epoch 5/20\n",
      "541/541 [==============================] - 1s 1ms/step - loss: 0.1884 - acc: 0.9224\n",
      "Epoch 6/20\n",
      "541/541 [==============================] - 1s 1ms/step - loss: 0.1614 - acc: 0.9224\n",
      "Epoch 7/20\n",
      "541/541 [==============================] - 1s 1ms/step - loss: 0.1598 - acc: 0.9372\n",
      "Epoch 8/20\n",
      "541/541 [==============================] - 1s 1ms/step - loss: 0.1462 - acc: 0.9335\n",
      "Epoch 9/20\n",
      "541/541 [==============================] - 1s 1ms/step - loss: 0.1369 - acc: 0.9464\n",
      "Epoch 10/20\n",
      "541/541 [==============================] - 1s 1ms/step - loss: 0.1365 - acc: 0.9372\n",
      "Epoch 11/20\n",
      "541/541 [==============================] - 1s 1ms/step - loss: 0.1287 - acc: 0.9427\n",
      "Epoch 12/20\n",
      "541/541 [==============================] - 1s 1ms/step - loss: 0.1218 - acc: 0.9556\n",
      "Epoch 13/20\n",
      "541/541 [==============================] - 1s 1ms/step - loss: 0.1139 - acc: 0.9538\n",
      "Epoch 14/20\n",
      "541/541 [==============================] - 1s 1ms/step - loss: 0.1216 - acc: 0.9556\n",
      "Epoch 15/20\n",
      "541/541 [==============================] - 1s 1ms/step - loss: 0.1033 - acc: 0.9704\n",
      "Epoch 16/20\n",
      "541/541 [==============================] - 1s 1ms/step - loss: 0.0881 - acc: 0.9612\n",
      "Epoch 17/20\n",
      "541/541 [==============================] - 1s 2ms/step - loss: 0.1061 - acc: 0.9630\n",
      "Epoch 18/20\n",
      "541/541 [==============================] - 1s 2ms/step - loss: 0.1124 - acc: 0.9464\n",
      "Epoch 19/20\n",
      "541/541 [==============================] - 1s 1ms/step - loss: 0.1011 - acc: 0.9538\n",
      "Epoch 20/20\n",
      "541/541 [==============================] - 1s 1ms/step - loss: 0.0898 - acc: 0.9667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a36243a58>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(np.array(X_train).reshape((*X_train.shape,1)),np.array(y_train).reshape((*y_train.shape,1)),epochs=20,batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>350</th>\n",
       "      <th>351</th>\n",
       "      <th>352</th>\n",
       "      <th>353</th>\n",
       "      <th>354</th>\n",
       "      <th>355</th>\n",
       "      <th>356</th>\n",
       "      <th>357</th>\n",
       "      <th>358</th>\n",
       "      <th>359</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.468719</td>\n",
       "      <td>0.471194</td>\n",
       "      <td>0.473923</td>\n",
       "      <td>0.472880</td>\n",
       "      <td>0.026460</td>\n",
       "      <td>0.480051</td>\n",
       "      <td>0.530707</td>\n",
       "      <td>0.507642</td>\n",
       "      <td>0.536421</td>\n",
       "      <td>0.162060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506608</td>\n",
       "      <td>0.502931</td>\n",
       "      <td>0.027454</td>\n",
       "      <td>0.654104</td>\n",
       "      <td>0.551421</td>\n",
       "      <td>0.477261</td>\n",
       "      <td>0.509144</td>\n",
       "      <td>0.197641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.019363</td>\n",
       "      <td>0.020412</td>\n",
       "      <td>0.019597</td>\n",
       "      <td>0.020482</td>\n",
       "      <td>0.135017</td>\n",
       "      <td>0.337802</td>\n",
       "      <td>0.467295</td>\n",
       "      <td>0.019374</td>\n",
       "      <td>0.018325</td>\n",
       "      <td>0.011924</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019838</td>\n",
       "      <td>0.019439</td>\n",
       "      <td>0.079544</td>\n",
       "      <td>0.523487</td>\n",
       "      <td>0.482383</td>\n",
       "      <td>0.019934</td>\n",
       "      <td>0.019084</td>\n",
       "      <td>0.013919</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.014752</td>\n",
       "      <td>0.015711</td>\n",
       "      <td>0.015098</td>\n",
       "      <td>0.015733</td>\n",
       "      <td>0.022026</td>\n",
       "      <td>0.521980</td>\n",
       "      <td>0.233387</td>\n",
       "      <td>0.009060</td>\n",
       "      <td>0.007858</td>\n",
       "      <td>0.018869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016889</td>\n",
       "      <td>0.016866</td>\n",
       "      <td>0.025077</td>\n",
       "      <td>0.593370</td>\n",
       "      <td>0.236473</td>\n",
       "      <td>0.014543</td>\n",
       "      <td>0.010879</td>\n",
       "      <td>0.012098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0.014621</td>\n",
       "      <td>0.015826</td>\n",
       "      <td>0.014880</td>\n",
       "      <td>0.015922</td>\n",
       "      <td>0.040869</td>\n",
       "      <td>0.459413</td>\n",
       "      <td>0.236596</td>\n",
       "      <td>0.015448</td>\n",
       "      <td>0.015785</td>\n",
       "      <td>0.022562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010876</td>\n",
       "      <td>0.010886</td>\n",
       "      <td>0.012705</td>\n",
       "      <td>0.357955</td>\n",
       "      <td>0.234835</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0.014711</td>\n",
       "      <td>0.016287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>0.021356</td>\n",
       "      <td>0.024041</td>\n",
       "      <td>0.021415</td>\n",
       "      <td>0.023068</td>\n",
       "      <td>0.107104</td>\n",
       "      <td>0.472226</td>\n",
       "      <td>0.467663</td>\n",
       "      <td>0.020150</td>\n",
       "      <td>0.017606</td>\n",
       "      <td>0.043923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027143</td>\n",
       "      <td>0.029643</td>\n",
       "      <td>0.092109</td>\n",
       "      <td>0.542929</td>\n",
       "      <td>0.467004</td>\n",
       "      <td>0.022363</td>\n",
       "      <td>0.019814</td>\n",
       "      <td>0.052748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 360 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "23   0.468719  0.471194  0.473923  0.472880  0.026460  0.480051  0.530707   \n",
       "182  0.019363  0.020412  0.019597  0.020482  0.135017  0.337802  0.467295   \n",
       "207  0.014752  0.015711  0.015098  0.015733  0.022026  0.521980  0.233387   \n",
       "210  0.014621  0.015826  0.014880  0.015922  0.040869  0.459413  0.236596   \n",
       "231  0.021356  0.024041  0.021415  0.023068  0.107104  0.472226  0.467663   \n",
       "\n",
       "            7         8         9  ...       350       351       352  \\\n",
       "23   0.507642  0.536421  0.162060  ...  0.506608  0.502931  0.027454   \n",
       "182  0.019374  0.018325  0.011924  ...  0.019838  0.019439  0.079544   \n",
       "207  0.009060  0.007858  0.018869  ...  0.016889  0.016866  0.025077   \n",
       "210  0.015448  0.015785  0.022562  ...  0.010876  0.010886  0.012705   \n",
       "231  0.020150  0.017606  0.043923  ...  0.027143  0.029643  0.092109   \n",
       "\n",
       "          353       354       355       356       357  358  359  \n",
       "23   0.654104  0.551421  0.477261  0.509144  0.197641  0.0  0.0  \n",
       "182  0.523487  0.482383  0.019934  0.019084  0.013919  0.0  0.0  \n",
       "207  0.593370  0.236473  0.014543  0.010879  0.012098  0.0  0.0  \n",
       "210  0.357955  0.234835  0.014724  0.014711  0.016287  0.0  0.0  \n",
       "231  0.542929  0.467004  0.022363  0.019814  0.052748  0.0  0.0  \n",
       "\n",
       "[5 rows x 360 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(trainX, trainy,testX,testy):\n",
    "    verbose, epochs, batch_size = 1, 10, 32\n",
    "    trainX.reshape(trainX[0], trainX[1], 1)\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[0], trainX.shape[1], trainy.shape[0]\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape = (trainX[1], 1)))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\t# fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "\t# evaluate model\n",
    "    accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "\treturn accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import csv\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "from datetime import datetime, timedelta, date\n",
    "import requests\n",
    "import json \n",
    "import ta\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelling_multiclass(dataframe):\n",
    "    \"\"\"This generates labels for the dataframes we wish to predict price.\n",
    "    A label of 1 suggests an increase in price between months while a label of 0 indicates\n",
    "    a decrease in price. If the current price is greater than the previous price then a\"\"\"\n",
    "    dataframe = dataframe.apply(pd.to_numeric)\n",
    "    #introduce the absolute price change as a variable\n",
    "    dataframe['ATR'] = ta.volatility.average_true_range(dataframe.High, dataframe.Low, dataframe.Close, n=14, \n",
    "                                                        fillna=True)\n",
    "    \n",
    "    #calculate the percentage change of ATR between months \n",
    "    dataframe['ATR_%_change'] = abs(dataframe['ATR'].pct_change())\n",
    "    \n",
    "    #calculate the average ATR pct change\n",
    "    average_ATR_pct_change = dataframe['ATR_%_change'].mean()\n",
    "    \n",
    "    \n",
    "    \n",
    "    empty_dict = dict()\n",
    "    prev_close =0\n",
    "    counter = 0\n",
    "    \n",
    "    #print (dataframe.head(5))\n",
    "    \n",
    "    for index,cols in dataframe.iterrows():\n",
    "        \n",
    "        counter +=1\n",
    "        \n",
    "        current_close = cols['Close']\n",
    "        ATR_price_change = cols['ATR_%_change']\n",
    "        \n",
    "        if (float(prev_close) <= float(current_close)) and (float(ATR_price_change) <= float(average_ATR_pct_change)):\n",
    "            \n",
    "            #signals an increase in price between last month and next month\n",
    "            \n",
    "            empty_dict[index] = 1\n",
    "        # 2 represents an increase that was strong greater than the average ATR   \n",
    "        elif (float(prev_close) <= float(current_close)) and (float(ATR_price_change) >= float(average_ATR_pct_change)):\n",
    "            empty_dict[index] = 2\n",
    "        \n",
    "        elif (float(prev_close) >= float(current_close)and (float(ATR_price_change) <= float(average_ATR_pct_change))):\n",
    "            empty_dict[index]=0\n",
    "            \n",
    "        #3 represents a decrease in the price that had a larger ATR    \n",
    "        elif (float(prev_close) >= float(current_close)and (float(ATR_price_change) >= float(average_ATR_pct_change))):\n",
    "            empty_dict[index] = 3\n",
    "        \n",
    "        else:\n",
    "            empty_dict[index]= 0\n",
    "            \n",
    "\n",
    "        #reassign prev close to the current close     \n",
    "        prev_close = current_close\n",
    "    \n",
    "    return empty_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in dataframes with MONTHLY data \n",
    "MSFT = pd.read_csv(r\"/Users/fahad/project_repo/data/external/MSFT_monthly.csv\")\n",
    "AAPL = pd.read_csv(r\"/Users/fahad/project_repo/data/external/AAPL_monthly.csv\")\n",
    "AMZN = pd.read_csv(r\"/Users/fahad/project_repo/data/external/AMZN_monthly.csv\")\n",
    "\n",
    "#GIVE COLUMN NAMES \n",
    "MSFT.columns = ['Date','Open','High','Low','Close','Volume']\n",
    "AAPL.columns = ['Date','Open','High','Low','Close','Volume']\n",
    "AMZN.columns = ['Date','Open','High','Low','Close','Volume']\n",
    "\n",
    "\n",
    "#set date column as the index\n",
    "MSFT = MSFT.set_index(['Date'])\n",
    "AAPL = AAPL.set_index(['Date'])\n",
    "AMZN = AMZN.set_index(['Date'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort from old to new\n",
    "MSFT = MSFT.sort_index()\n",
    "AAPL = AAPL.sort_index()\n",
    "AMZN = AMZN.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLIT THE DATA LEARN FROM 1998 TO 2015 AND PREDICT THE REMAINING 4 YEARS \n",
    "#TRAINING DATA AND VALIDATION DATA \n",
    "MSFT_98_to_2015 = MSFT[:206]\n",
    "AAPL_98_to_2015 = AAPL[:206]\n",
    "AMZN_98_to_2015 = AMZN[:206]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST DATA \n",
    "MSFT_2015_to_2019 = MSFT[206:]\n",
    "AAPL_2015_to_2019 = AAPL[206:]\n",
    "AMZN_2015_to_2019 = AMZN[206:]\n",
    "\n",
    "export_MSFT= MSFT_2015_to_2019.to_csv(r'MSFT_15_to_19.csv')\n",
    "\n",
    "export_AAPL= AAPL_2015_to_2019.to_csv(r'AAPL_15_to_19.csv')\n",
    "\n",
    "export_AMZN = AMZN_2015_to_2019.to_csv(r'AMZN_15_to_19.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING  DATA 1998 TO 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#returns the a dictionary object with the dates and corresponding buy/sell signals from 98 to 2015 with labels attached\n",
    "#takes empty dict as first param, and dataframe object with OHLCV as second argument\n",
    "\n",
    "#dictionaries with dates and labels for the \n",
    "MSFT_98_2015_labelled = labelling_multiclass(MSFT_98_to_2015)\n",
    "AAPL_98_2015_labelled = labelling_multiclass(AAPL_98_to_2015)\n",
    "AMZN_98_2015_labelled = labelling_multiclass(AMZN_98_to_2015)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dicts containing the labels \n",
    "MSFT_2015_2019_labelled = labelling_multiclass(MSFT_2015_to_2019)\n",
    "AAPL_2015_2019_labelled = labelling_multiclass(AAPL_2015_to_2019)\n",
    "AMZN_2015_2019_labelled = labelling_multiclass(AMZN_2015_to_2019)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fahad/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/fahad/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/fahad/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/fahad/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/fahad/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/Users/fahad/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#add the label values to the dataframe\n",
    "MSFT_98_to_2015['Labels'] = MSFT_98_2015_labelled.values()\n",
    "AAPL_98_to_2015['Labels'] = AAPL_98_2015_labelled.values()\n",
    "AMZN_98_to_2015['Labels'] = AMZN_98_2015_labelled.values()\n",
    "\n",
    "MSFT_2015_to_2019['Labels'] = MSFT_2015_2019_labelled.values()\n",
    "AAPL_2015_to_2019['Labels'] = AAPL_2015_2019_labelled.values()\n",
    "AMZN_2015_to_2019['Labels'] = AMZN_2015_2019_labelled.values()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT THE DAILY DATAFRAMES \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ['Date', 'Open','High','Low','Close','Volume','RSI','MACD','Ichimoku_Span_A','Ichimoku_Span_B','ATR',\n",
    "         'BB_High_Indicator','BB_Low_Indicator']\n",
    "\n",
    "MSFT_df = pd.read_csv(r\"/Users/fahad/project_repo/data/interim/MSFT.csv\", usecols=fields)\n",
    "AAPL_df = pd.read_csv(r\"/Users/fahad/project_repo/data/interim/AAPL.csv\", usecols=fields)\n",
    "AMZN_df = pd.read_csv(r\"/Users/fahad/project_repo/data/interim/AMZN.csv\", usecols=fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEED TO split the dai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.Neural_Network_Preparation import get_ndays_monthly_flattened\n",
    "\n",
    "#get the flattened dict for microsoft, appl and amzn that we will train on, \n",
    "MSFT_98_to_2015_flattened_dict = get_ndays_monthly_flattened(MSFT_98_to_2015,MSFT_df,30)\n",
    "\n",
    "AAPL_98_to_2015_flattened_dict = get_ndays_monthly_flattened(AAPL_98_to_2015, AAPL_df,30)\n",
    "\n",
    "AMZN_98_to_2015_flattened_dict = get_ndays_monthly_flattened(AMZN_98_to_2015, AMZN_df, 30)\n",
    "\n",
    "\n",
    "\n",
    "MSFT_15_to_2019_flattened_dict = get_ndays_monthly_flattened(MSFT_2015_to_2019,MSFT_df,30)\n",
    "\n",
    "AAPL_15_to_2019_flattened_dict = get_ndays_monthly_flattened(AAPL_2015_to_2019,AAPL_df,30)\n",
    "\n",
    "AMZN_15_to_2019_flattened_dict = get_ndays_monthly_flattened(AMZN_2015_to_2019, AMZN_df,30)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign the labels to pandas dataframe objects and give label title for the 98 to 2015 data\n",
    "MSFT_labels_98_to_2015_df = pd.Series(MSFT_98_2015_labelled).to_frame(\"Label\")\n",
    "AAPL_labels_98_to_2015_df = pd.Series(AAPL_98_2015_labelled ).to_frame(\"Label\")\n",
    "AMZN_labels_98_to_2015_df = pd.Series(AMZN_98_2015_labelled ).to_frame(\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign the labels for the dates from 2015 to 2019 to a dataframe \n",
    "MSFT_labels_2015_to_2019_df = pd.Series(MSFT_2015_2019_labelled).to_frame(\"Label\")\n",
    "AAPL_labels_2015_to_2019_df = pd.Series(AAPL_2015_2019_labelled ).to_frame(\"Label\")\n",
    "AMZN_labels_2015_to_2019_df = pd.Series(AMZN_2015_2019_labelled ).to_frame(\"Label\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create flattened dataframes with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create separate dataframes for the training data and the test data \n",
    "\n",
    "#convert the flattened dictionaries to dataframes \n",
    "flattened_df_MSFT_98_to_2015 = pd.DataFrame.from_dict(MSFT_98_to_2015_flattened_dict).T\n",
    "flattened_df_AAPL_98_to_2015 = pd.DataFrame.from_dict(AAPL_98_to_2015_flattened_dict).T\n",
    "flattened_df_AMZN_98_to_2015 = pd.DataFrame.from_dict(AMZN_98_to_2015_flattened_dict).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the flattened dictionaries to dataframes \n",
    "flattened_df_MSFT_2015_to_2019 = pd.DataFrame.from_dict(MSFT_15_to_2019_flattened_dict).T\n",
    "flattened_df_AAPL_2015_to_2019 = pd.DataFrame.from_dict(AAPL_15_to_2019_flattened_dict).T\n",
    "flattened_df_AMZN_2015_to_2019 = pd.DataFrame.from_dict(AMZN_15_to_2019_flattened_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'flattened_df_MSFT_98_to_2015' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-47a47c76ab4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#merge the dataframes on the index 'Date', and ensure that only the dates present in the flattened dataframe are carried over\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mflattened_df_MSFT_98_to_2015\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflattened_df_MSFT_98_to_2015\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMSFT_labels_98_to_2015_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mflattened_df_AAPL_98_to_2015\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflattened_df_AAPL_98_to_2015\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAAPL_labels_98_to_2015_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mflattened_df_AMZN_98_to_2015\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflattened_df_AMZN_98_to_2015\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAMZN_labels_98_to_2015_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'flattened_df_MSFT_98_to_2015' is not defined"
     ]
    }
   ],
   "source": [
    "#merge the dataframes on the index 'Date', and ensure that only the dates present in the flattened dataframe are carried over\n",
    "\n",
    "flattened_df_MSFT_98_to_2015 = flattened_df_MSFT_98_to_2015.merge(MSFT_labels_98_to_2015_df, left_index=True, right_index=True)\n",
    "flattened_df_AAPL_98_to_2015 = flattened_df_AAPL_98_to_2015.merge(AAPL_labels_98_to_2015_df, left_index=True, right_index=True)\n",
    "flattened_df_AMZN_98_to_2015 = flattened_df_AMZN_98_to_2015.merge(AMZN_labels_98_to_2015_df, left_index=True, right_index=True)\n",
    "\n",
    "flattened_df_MSFT_2015_to_2019 = flattened_df_MSFT_2015_to_2019.merge(MSFT_labels_2015_to_2019_df, left_index=True, right_index=True)\n",
    "flattened_df_AAPL_2015_to_2019 = flattened_df_AAPL_2015_to_2019.merge(AAPL_labels_2015_to_2019_df, left_index=True, right_index=True)\n",
    "flattened_df_AMZN_2015_to_2019 = flattened_df_AMZN_2015_to_2019.merge(AMZN_labels_2015_to_2019_df, left_index=True, right_index=True)\n",
    "\n",
    "flattened_df_MSFT_98_to_2015\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the dataframes as CSV's \n",
    "export_MSFT_98= flattened_df_MSFT_98_to_2015.to_csv(r'MSFT_flat_98_to_2015.csv')\n",
    "export_AMZN_98= flattened_df_AAPL_98_to_2015.to_csv(r'AMZN_flat_98_to_2015.csv') \n",
    "export_AAPL_98= flattened_df_AMZN_98_to_2015.to_csv(r'AAPL_flat_98_to_2015.csv')\n",
    "\n",
    "\n",
    "export_MSFT_15= flattened_df_MSFT_2015_to_2019.to_csv(r'MSFT_flat_2015_2019.csv')\n",
    "export_AAPL_15= flattened_df_AAPL_2015_to_2019.to_csv(r'AAPL_flat_2015_2019.csv')\n",
    "export_AMZN_15= flattened_df_AMZN_2015_to_2019.to_csv(r'AMZN_flat_2015_2019.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
